{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jx/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "np.random.seed(1337) # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D,Convolution2D, MaxPooling1D\n",
    "from keras.layers import merge\n",
    "# from keras.layers.merge import Concatenate\n",
    "from keras.regularizers import l2, activity_l1\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61340, 4, 113)\n",
      "[1 0 0 ..., 0 0 0]\n",
      "[[[0 0 0 ..., 0 0 0]\n",
      "  [0 0 1 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 1 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 1 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 0 0]]\n",
      "\n",
      " ..., \n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 1 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 1 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 0 0]]\n",
      "\n",
      " [[0 0 0 ..., 0 0 0]\n",
      "  [0 0 1 ..., 0 0 0]\n",
      "  [0 1 0 ..., 0 0 0]\n",
      "  [1 0 0 ..., 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "validmat = scipy.io.loadmat('/Users/jx/Documents/FACSseq/YFSIVc/sTRSV_valid.mat')\n",
    "testmat = scipy.io.loadmat('/Users/jx/Documents/FACSseq/YFSIVc/sTRSV_valid.mat')\n",
    "trainmat = scipy.io.loadmat('/Users/jx/Documents/FACSseq/YFSIVc/sTRSV_train.mat')\n",
    "\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['tr'][0][0][0]),axes=(0,2,1))\n",
    "# X_train = np.expand_dims(X_train,axis=(2))\n",
    "y_train = np.array(trainmat['tr'][0][0][1]).squeeze()\n",
    "# y_train = y_train.reshape((-1, 1))\n",
    "# y_train.squeeze()\n",
    "print X_train.shape\n",
    "print y_train\n",
    "print X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "compiling model\n",
      "Train on 61340 samples, validate on 6816 samples\n",
      "Epoch 1/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.3337 - acc: 0.9124Epoch 00000: val_loss improved from inf to 0.28301, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 209s - loss: 0.3334 - acc: 0.9124 - val_loss: 0.2830 - val_acc: 0.9136\n",
      "Epoch 2/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2806 - acc: 0.9124Epoch 00001: val_loss improved from 0.28301 to 0.26770, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 209s - loss: 0.2807 - acc: 0.9124 - val_loss: 0.2677 - val_acc: 0.9136\n",
      "Epoch 3/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2713 - acc: 0.9123Epoch 00002: val_loss improved from 0.26770 to 0.26331, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 208s - loss: 0.2713 - acc: 0.9123 - val_loss: 0.2633 - val_acc: 0.9136\n",
      "Epoch 4/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2672 - acc: 0.9122Epoch 00003: val_loss improved from 0.26331 to 0.26024, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 212s - loss: 0.2671 - acc: 0.9123 - val_loss: 0.2602 - val_acc: 0.9136\n",
      "Epoch 5/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2639 - acc: 0.9125Epoch 00004: val_loss improved from 0.26024 to 0.25819, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 210s - loss: 0.2640 - acc: 0.9124 - val_loss: 0.2582 - val_acc: 0.9136\n",
      "Epoch 6/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2619 - acc: 0.9126Epoch 00005: val_loss improved from 0.25819 to 0.25620, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 212s - loss: 0.2621 - acc: 0.9126 - val_loss: 0.2562 - val_acc: 0.9139\n",
      "Epoch 7/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2602 - acc: 0.9120Epoch 00006: val_loss did not improve\n",
      "61340/61340 [==============================] - 212s - loss: 0.2604 - acc: 0.9121 - val_loss: 0.2572 - val_acc: 0.9140\n",
      "Epoch 8/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2574 - acc: 0.9121Epoch 00007: val_loss improved from 0.25620 to 0.25248, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 210s - loss: 0.2574 - acc: 0.9122 - val_loss: 0.2525 - val_acc: 0.9143\n",
      "Epoch 9/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2569 - acc: 0.9129Epoch 00008: val_loss did not improve\n",
      "61340/61340 [==============================] - 209s - loss: 0.2569 - acc: 0.9129 - val_loss: 0.2536 - val_acc: 0.9139\n",
      "Epoch 10/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2550 - acc: 0.9132Epoch 00009: val_loss improved from 0.25248 to 0.25054, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 210s - loss: 0.2548 - acc: 0.9132 - val_loss: 0.2505 - val_acc: 0.9140\n",
      "Epoch 11/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2536 - acc: 0.9132Epoch 00010: val_loss did not improve\n",
      "61340/61340 [==============================] - 213s - loss: 0.2534 - acc: 0.9132 - val_loss: 0.2548 - val_acc: 0.9142\n",
      "Epoch 12/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2540 - acc: 0.9128Epoch 00011: val_loss improved from 0.25054 to 0.24980, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 223s - loss: 0.2539 - acc: 0.9128 - val_loss: 0.2498 - val_acc: 0.9149\n",
      "Epoch 13/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2526 - acc: 0.9129Epoch 00012: val_loss did not improve\n",
      "61340/61340 [==============================] - 262s - loss: 0.2524 - acc: 0.9130 - val_loss: 0.2522 - val_acc: 0.9140\n",
      "Epoch 14/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2511 - acc: 0.9136Epoch 00013: val_loss improved from 0.24980 to 0.24813, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 350s - loss: 0.2512 - acc: 0.9135 - val_loss: 0.2481 - val_acc: 0.9137\n",
      "Epoch 15/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2489 - acc: 0.9135Epoch 00014: val_loss improved from 0.24813 to 0.24809, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 349s - loss: 0.2491 - acc: 0.9134 - val_loss: 0.2481 - val_acc: 0.9145\n",
      "Epoch 16/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2492 - acc: 0.9141Epoch 00015: val_loss did not improve\n",
      "61340/61340 [==============================] - 347s - loss: 0.2489 - acc: 0.9143 - val_loss: 0.2507 - val_acc: 0.9151\n",
      "Epoch 17/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2483 - acc: 0.9141Epoch 00016: val_loss improved from 0.24809 to 0.24787, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 344s - loss: 0.2482 - acc: 0.9141 - val_loss: 0.2479 - val_acc: 0.9134\n",
      "Epoch 18/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2474 - acc: 0.9134Epoch 00017: val_loss did not improve\n",
      "61340/61340 [==============================] - 341s - loss: 0.2475 - acc: 0.9135 - val_loss: 0.2504 - val_acc: 0.9142\n",
      "Epoch 19/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2469 - acc: 0.9139Epoch 00018: val_loss did not improve\n",
      "61340/61340 [==============================] - 338s - loss: 0.2467 - acc: 0.9140 - val_loss: 0.2486 - val_acc: 0.9142\n",
      "Epoch 20/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2484 - acc: 0.9133Epoch 00019: val_loss did not improve\n",
      "61340/61340 [==============================] - 337s - loss: 0.2485 - acc: 0.9133 - val_loss: 0.2503 - val_acc: 0.9146\n",
      "Epoch 21/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2463 - acc: 0.9144Epoch 00020: val_loss improved from 0.24787 to 0.24744, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 330s - loss: 0.2465 - acc: 0.9143 - val_loss: 0.2474 - val_acc: 0.9136\n",
      "Epoch 22/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2462 - acc: 0.9138Epoch 00021: val_loss did not improve\n",
      "61340/61340 [==============================] - 326s - loss: 0.2465 - acc: 0.9137 - val_loss: 0.2482 - val_acc: 0.9140\n",
      "Epoch 23/500\n",
      "60928/61340 [============================>.] - ETA: 2s - loss: 0.2451 - acc: 0.9146Epoch 00022: val_loss did not improve\n",
      "61340/61340 [==============================] - 324s - loss: 0.2451 - acc: 0.9146 - val_loss: 0.2508 - val_acc: 0.9133\n",
      "Epoch 24/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2453 - acc: 0.9140Epoch 00023: val_loss improved from 0.24744 to 0.24573, saving model to bestmodel3D_classify.hdf5\n",
      "61340/61340 [==============================] - 317s - loss: 0.2453 - acc: 0.9141 - val_loss: 0.2457 - val_acc: 0.9142\n",
      "Epoch 25/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2448 - acc: 0.9138Epoch 00024: val_loss did not improve\n",
      "61340/61340 [==============================] - 313s - loss: 0.2449 - acc: 0.9138 - val_loss: 0.2470 - val_acc: 0.9140\n",
      "Epoch 26/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2439 - acc: 0.9138Epoch 00025: val_loss did not improve\n",
      "61340/61340 [==============================] - 308s - loss: 0.2439 - acc: 0.9137 - val_loss: 0.2492 - val_acc: 0.9133\n",
      "Epoch 27/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2452 - acc: 0.9141Epoch 00026: val_loss did not improve\n",
      "61340/61340 [==============================] - 303s - loss: 0.2454 - acc: 0.9140 - val_loss: 0.2508 - val_acc: 0.9139\n",
      "Epoch 28/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2437 - acc: 0.9144Epoch 00027: val_loss did not improve\n",
      "61340/61340 [==============================] - 281s - loss: 0.2439 - acc: 0.9143 - val_loss: 0.2528 - val_acc: 0.9137\n",
      "Epoch 29/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2444 - acc: 0.9143Epoch 00028: val_loss did not improve\n",
      "61340/61340 [==============================] - 234s - loss: 0.2445 - acc: 0.9142 - val_loss: 0.2550 - val_acc: 0.9129\n",
      "Epoch 30/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2443 - acc: 0.9139Epoch 00029: val_loss did not improve\n",
      "61340/61340 [==============================] - 230s - loss: 0.2444 - acc: 0.9139 - val_loss: 0.2504 - val_acc: 0.9137\n",
      "Epoch 31/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2437 - acc: 0.9145Epoch 00030: val_loss did not improve\n",
      "61340/61340 [==============================] - 227s - loss: 0.2439 - acc: 0.9143 - val_loss: 0.2534 - val_acc: 0.9148\n",
      "Epoch 32/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2429 - acc: 0.9146Epoch 00031: val_loss did not improve\n",
      "61340/61340 [==============================] - 222s - loss: 0.2428 - acc: 0.9147 - val_loss: 0.2513 - val_acc: 0.9126\n",
      "Epoch 33/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2427 - acc: 0.9143Epoch 00032: val_loss did not improve\n",
      "61340/61340 [==============================] - 222s - loss: 0.2424 - acc: 0.9145 - val_loss: 0.2511 - val_acc: 0.9148\n",
      "Epoch 34/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2425 - acc: 0.9143Epoch 00033: val_loss did not improve\n",
      "61340/61340 [==============================] - 214s - loss: 0.2426 - acc: 0.9144 - val_loss: 0.2517 - val_acc: 0.9148\n",
      "Epoch 35/500\n",
      "60928/61340 [============================>.] - ETA: 1s - loss: 0.2422 - acc: 0.9146Epoch 00034: val_loss did not improve\n",
      "61340/61340 [==============================] - 210s - loss: 0.2423 - acc: 0.9146 - val_loss: 0.2489 - val_acc: 0.9146\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lr = 1e-5#learning rate\n",
    "reg = 1e-3\n",
    "print 'building model'\n",
    "nb_filters=32\n",
    "model = Sequential()\n",
    "# model.add(LSTM(256,  W_regularizer=l2(reg),return_sequences=True, input_shape=(4,113)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(LSTM(40,  W_regularizer=l2(reg)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# model.add(LSTM(32,24, W_regularizer=l2(reg),input_shape=(X_train.shape[0], X_train.shape[1], X_train.shape[2]))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# conv1=Sequential()\n",
    "model.add(Convolution1D(8,256, border_mode='same', W_regularizer=l2(reg),input_shape=(4,113))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution1D(8,64, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution1D(8,64, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution1D(8,64, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "# model.add(Convolution1D(8,64, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Convolution1D(4,32, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.05))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# model.add(Dense(1000))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "print 'compiling model'\n",
    "# model.compile(loss='mse', optimizer='adam', metrics=[\"mse\"])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"bestmodel3D_classify.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "X_valid=np.transpose(validmat['tr'][0][0][0],axes=(0,2,1))\n",
    "# X_valid=np.expand_dims(X_valid)\n",
    "y_valid=np.array(validmat['tr'][0][0][1]).squeeze()\n",
    "\n",
    "\n",
    "history=model.fit(X_train, y_train, batch_size=512, nb_epoch=500, shuffle=True, validation_data=(X_valid, y_valid),callbacks=[checkpointer,earlystopper])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "61340/61340 [==============================] - 114s   \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_1 (Convolution1D)  (None, 4, 8)          231432      convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 4, 8)          0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4, 8)          0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 4, 8)          4104        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 8)          0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 8)          0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 4, 8)          4104        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4, 8)          0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4, 8)          0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 4, 8)          4104        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 4, 8)          0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4, 8)          0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 32)            0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             33          flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 243777\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "out=model.predict(X_train, batch_size=512,verbose=1)\n",
    "plt.plot(y_train,out,'ro')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12317,)\n",
      "0.674227100021\n",
      "0.407035704157\n",
      "-0.0509881643101\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "out=out.squeeze()\n",
    "print out.shape\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y_train, out)\n",
    "print r_value\n",
    "print slope\n",
    "print intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "6816/6816 [==============================] - 15s    \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution1d_1 (Convolution1D)  (None, 4, 8)          231432      convolution1d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 4, 8)          0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4, 8)          0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 4, 8)          4104        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 8)          0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 8)          0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 4, 8)          4104        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4, 8)          0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4, 8)          0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 4, 8)          4104        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 4, 8)          0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4, 8)          0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 32)            0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             33          flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 243777\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test=np.transpose(testmat['tr'][0][0][0],axes=(0,2,1))\n",
    "y_test=np.array(testmat['tr'][0][0][1]).squeeze()\n",
    "\n",
    "y_out=model.predict(X_test, batch_size=512,verbose=1)\n",
    "plt.plot(y_test,y_out,'ro')\n",
    "plt.ylabel('model prediction')\n",
    "plt.xlabel('FACS-seq data')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6816,)\n",
      "0.34013971057\n",
      "0.12461756668\n",
      "0.0737930304534\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "out=y_out.squeeze()\n",
    "print out.shape\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y_test, out)\n",
    "print r_value\n",
    "print slope\n",
    "print intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  64/6816 [..............................] - ETA: 16s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jx/anaconda2/lib/python2.7/site-packages/Keras-1.1.1-py2.7.egg/keras/models.py:666: UserWarning: The \"show_accuracy\" argument is deprecated, instead you should pass the \"accuracy\" metric to the model at compile time:\n",
      "`model.compile(optimizer, loss, metrics=[\"accuracy\"])`\n",
      "  warnings.warn('The \"show_accuracy\" argument is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6816/6816 [==============================] - 16s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24888177172328946, 0.914612676056338]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test,show_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

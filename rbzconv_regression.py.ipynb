{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "(48345, 2, 4, 113)\n",
      "(48345,)\n",
      "building model\n",
      "compiling model\n",
      "Train on 48345 samples, validate on 2553 samples\n",
      "Epoch 1/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 1.2786 - mean_squared_error: 1.2157Epoch 00000: val_loss improved from inf to 1.29952, saving model to bestmodel.hdf5\n",
      "48345/48345 [==============================] - 111s - loss: 1.2779 - mean_squared_error: 1.2151 - val_loss: 1.2995 - val_mean_squared_error: 1.2995\n",
      "Epoch 2/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 1.2055 - mean_squared_error: 1.1516Epoch 00001: val_loss improved from 1.29952 to 1.20779, saving model to bestmodel.hdf5\n",
      "48345/48345 [==============================] - 114s - loss: 1.2056 - mean_squared_error: 1.1518 - val_loss: 1.2078 - val_mean_squared_error: 1.2078\n",
      "Epoch 3/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 1.1623 - mean_squared_error: 1.1119Epoch 00002: val_loss improved from 1.20779 to 1.18384, saving model to bestmodel.hdf5\n",
      "48345/48345 [==============================] - 114s - loss: 1.1620 - mean_squared_error: 1.1116 - val_loss: 1.1838 - val_mean_squared_error: 1.1838\n",
      "Epoch 4/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 1.1196 - mean_squared_error: 1.0683Epoch 00003: val_loss did not improve\n",
      "48345/48345 [==============================] - 114s - loss: 1.1204 - mean_squared_error: 1.0691 - val_loss: 1.1951 - val_mean_squared_error: 1.1951\n",
      "Epoch 5/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 1.0772 - mean_squared_error: 1.0219Epoch 00004: val_loss did not improve\n",
      "48345/48345 [==============================] - 114s - loss: 1.0769 - mean_squared_error: 1.0216 - val_loss: 1.1995 - val_mean_squared_error: 1.1995\n",
      "Epoch 6/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 1.0242 - mean_squared_error: 0.9635Epoch 00005: val_loss did not improve\n",
      "48345/48345 [==============================] - 114s - loss: 1.0249 - mean_squared_error: 0.9642 - val_loss: 1.2375 - val_mean_squared_error: 1.2375\n",
      "Epoch 7/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.9737 - mean_squared_error: 0.9071Epoch 00006: val_loss did not improve\n",
      "48345/48345 [==============================] - 115s - loss: 0.9731 - mean_squared_error: 0.9065 - val_loss: 1.2604 - val_mean_squared_error: 1.2604\n",
      "Epoch 8/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.9401 - mean_squared_error: 0.8680Epoch 00007: val_loss did not improve\n",
      "48345/48345 [==============================] - 119s - loss: 0.9404 - mean_squared_error: 0.8683 - val_loss: 1.2289 - val_mean_squared_error: 1.2289\n",
      "Epoch 9/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.8977 - mean_squared_error: 0.8209Epoch 00008: val_loss did not improve\n",
      "48345/48345 [==============================] - 113s - loss: 0.8977 - mean_squared_error: 0.8208 - val_loss: 1.3159 - val_mean_squared_error: 1.3159\n",
      "Epoch 10/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.8700 - mean_squared_error: 0.7889Epoch 00009: val_loss did not improve\n",
      "48345/48345 [==============================] - 114s - loss: 0.8707 - mean_squared_error: 0.7896 - val_loss: 1.2673 - val_mean_squared_error: 1.2673\n",
      "Epoch 11/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.8461 - mean_squared_error: 0.7614Epoch 00010: val_loss did not improve\n",
      "48345/48345 [==============================] - 113s - loss: 0.8463 - mean_squared_error: 0.7616 - val_loss: 1.3726 - val_mean_squared_error: 1.3726\n",
      "Epoch 12/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.8298 - mean_squared_error: 0.7419Epoch 00011: val_loss did not improve\n",
      "48345/48345 [==============================] - 113s - loss: 0.8296 - mean_squared_error: 0.7417 - val_loss: 1.3892 - val_mean_squared_error: 1.3892\n",
      "Epoch 13/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.8071 - mean_squared_error: 0.7165Epoch 00012: val_loss did not improve\n",
      "48345/48345 [==============================] - 112s - loss: 0.8073 - mean_squared_error: 0.7168 - val_loss: 1.3012 - val_mean_squared_error: 1.3012\n",
      "Epoch 14/500\n",
      "48128/48345 [============================>.] - ETA: 0s - loss: 0.7926 - mean_squared_error: 0.6996Epoch 00013: val_loss did not improve\n",
      "48345/48345 [==============================] - 111s - loss: 0.7927 - mean_squared_error: 0.6997 - val_loss: 1.2778 - val_mean_squared_error: 1.2778\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1213a2510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[118]:\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "np.random.seed(1337) # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling1D, AtrousConvolution1D\n",
    "from keras.regularizers import l2, activity_l1\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# from seya.layers.recurrent import Bidirectional # after git clone need to python setup.py install again\n",
    "# from keras.utils.layer_utils import print_layer_shapes\n",
    "\n",
    "\n",
    "\n",
    "print 'loading data'\n",
    "# trainmat = h5py.File('/Users/jx/Downloads/deepsea_train/train.mat')\n",
    "validmat = scipy.io.loadmat('/Users/jx/Documents/rbznn/valid_enriched_rbzcontinuous_nomemorize_wstruct.mat')\n",
    "# testmat = scipy.io.loadmat('/Users/jx/Documents/rbznn/test_enriched_rbzcontinuous_nomemorize.mat')\n",
    "trainmat = scipy.io.loadmat('/Users/jx/Documents/rbznn/train_enriched_rbzcontinuous_nomemorize_wstruct.mat')\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['tr'][0][0][0]),axes=(0,2,3,1))\n",
    "y_train = np.array(trainmat['tr'][0][0][1]).squeeze()\n",
    "# y_train = y_train.reshape((-1, 1))\n",
    "# y_train.squeeze()\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "\n",
    "\n",
    "\n",
    "lr = 1e-6#learning rate\n",
    "reg = 1e-3\n",
    "print 'building model'\n",
    "nb_filters=32\n",
    "model = Sequential()\n",
    "# model.add(LSTM(32,  W_regularizer=l2(reg),return_sequences=True, input_shape=(4, 113)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(64,  W_regularizer=l2(reg),return_sequences=True)) # return sequences is needed for stacking\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128,  W_regularizer=l2(reg)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(30))\n",
    "# model.add(Flatten( input_shape=(4,113)))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model.add(Convolution2D(32, 2,29, border_mode='same', W_regularizer=l2(reg), input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(32, 2,4, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(32, 2,4, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# model.add(Dense(30))\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "\n",
    "print 'compiling model'\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"bestmodel.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "X_valid=np.transpose(validmat['tr'][0][0][0],axes=(0,2,3,1))\n",
    "y_valid=np.array(validmat['tr'][0][0][1]).squeeze()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, nb_epoch=500, shuffle=True, validation_data=(X_valid, y_valid),callbacks=[checkpointer,earlystopper])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "46080/46658 [============================>.] - ETA: 0s____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "flatten_38 (Flatten)             (None, 452)           0           flatten_input_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_64 (Dense)                 (None, 10)            4530        flatten_38[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_65 (Dense)                 (None, 1)             11          dense_64[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_66 (Dense)                 (None, 1)             2           dense_65[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 4543\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "out=model.predict(X_train, batch_size=512,verbose=1)\n",
    "plt.plot(y_train,out,'ro')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "2553/2553 [==============================] - 2s     \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_4 (Convolution2D)  (None, 32, 4, 113)    3744        convolution2d_input_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 32, 4, 113)    0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 32, 4, 113)    0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 32, 4, 113)    8224        dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 32, 4, 113)    0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 32, 4, 113)    0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_6 (Convolution2D)  (None, 32, 4, 113)    8224        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 32, 4, 113)    0           convolution2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 32, 4, 113)    0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 14464)         0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             14465       flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 34657\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "out=model.predict(X_valid, batch_size=512,verbose=1)\n",
    "plt.plot(y_valid,out,'ro')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

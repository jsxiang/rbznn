{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "np.random.seed(1337) # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D,Convolution2D, MaxPooling1D\n",
    "from keras.layers import merge\n",
    "# from keras.layers.merge import Concatenate\n",
    "from keras.regularizers import l2, activity_l1\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "import keras\n",
    "print keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2385, 4, 113)\n",
      "(2385,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "validmat = scipy.io.loadmat('/Users/jx/Documents/FACSseq/YFSIVc/sTRSV_valid.mat')\n",
    "testmat = scipy.io.loadmat('/Users/jx/Documents/FACSseq/YFSIVc/sTRSV_valid.mat')\n",
    "trainmat = scipy.io.loadmat('/Users/jx/Documents/FACSseq/YFSIVc/sTRSV_train.mat')\n",
    "\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['tr'][0][0][0]),axes=(0,2,1))\n",
    "# X_train = np.expand_dims(X_train,axis=(2))\n",
    "y_train = np.array(trainmat['tr'][0][0][1]).squeeze()\n",
    "# y_train = y_train.reshape((-1, 1))\n",
    "# y_train.squeeze()\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "compiling model\n",
      "Train on 2385 samples, validate on 265 samples\n",
      "Epoch 1/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9855 - mean_squared_error: 0.9834Epoch 00000: val_loss improved from inf to 0.94210, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 1.0075 - mean_squared_error: 1.0054 - val_loss: 0.9421 - val_mean_squared_error: 0.9421\n",
      "Epoch 2/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9952 - mean_squared_error: 0.9931Epoch 00001: val_loss improved from 0.94210 to 0.92502, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.9935 - mean_squared_error: 0.9914 - val_loss: 0.9250 - val_mean_squared_error: 0.9250\n",
      "Epoch 3/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9290 - mean_squared_error: 0.9270Epoch 00002: val_loss improved from 0.92502 to 0.87350, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.9361 - mean_squared_error: 0.9340 - val_loss: 0.8735 - val_mean_squared_error: 0.8735\n",
      "Epoch 4/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8630 - mean_squared_error: 0.8610Epoch 00003: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8334 - mean_squared_error: 0.8314 - val_loss: 0.9263 - val_mean_squared_error: 0.9263\n",
      "Epoch 5/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8029 - mean_squared_error: 0.8009Epoch 00004: val_loss improved from 0.87350 to 0.85431, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.7889 - mean_squared_error: 0.7870 - val_loss: 0.8543 - val_mean_squared_error: 0.8543\n",
      "Epoch 6/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.7512 - mean_squared_error: 0.7493Epoch 00005: val_loss improved from 0.85431 to 0.76516, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.7507 - mean_squared_error: 0.7488 - val_loss: 0.7652 - val_mean_squared_error: 0.7652\n",
      "Epoch 7/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.6969 - mean_squared_error: 0.6949Epoch 00006: val_loss improved from 0.76516 to 0.75360, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.7018 - mean_squared_error: 0.6999 - val_loss: 0.7536 - val_mean_squared_error: 0.7536\n",
      "Epoch 8/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.6944 - mean_squared_error: 0.6925Epoch 00007: val_loss improved from 0.75360 to 0.75222, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.6998 - mean_squared_error: 0.6979 - val_loss: 0.7522 - val_mean_squared_error: 0.7522\n",
      "Epoch 9/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.6800 - mean_squared_error: 0.6781Epoch 00008: val_loss improved from 0.75222 to 0.73622, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.6767 - mean_squared_error: 0.6748 - val_loss: 0.7362 - val_mean_squared_error: 0.7362\n",
      "Epoch 10/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.6841 - mean_squared_error: 0.6822Epoch 00009: val_loss improved from 0.73622 to 0.71521, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.6707 - mean_squared_error: 0.6688 - val_loss: 0.7152 - val_mean_squared_error: 0.7152\n",
      "Epoch 11/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.6626 - mean_squared_error: 0.6608Epoch 00010: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.6568 - mean_squared_error: 0.6549 - val_loss: 0.7515 - val_mean_squared_error: 0.7515\n",
      "Epoch 12/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.6805 - mean_squared_error: 0.6787Epoch 00011: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.7052 - mean_squared_error: 0.7034 - val_loss: 0.7158 - val_mean_squared_error: 0.7158\n",
      "Epoch 13/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.7502 - mean_squared_error: 0.7484Epoch 00012: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.7429 - mean_squared_error: 0.7411 - val_loss: 0.7448 - val_mean_squared_error: 0.7448\n",
      "Epoch 14/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.7198 - mean_squared_error: 0.7180Epoch 00013: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.7191 - mean_squared_error: 0.7173 - val_loss: 0.9062 - val_mean_squared_error: 0.9062\n",
      "Epoch 15/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.7942 - mean_squared_error: 0.7924Epoch 00014: val_loss improved from 0.71521 to 0.69762, saving model to bestmodel3D.hdf5\n",
      "2385/2385 [==============================] - 1s - loss: 0.8051 - mean_squared_error: 0.8033 - val_loss: 0.6976 - val_mean_squared_error: 0.6976\n",
      "Epoch 16/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8303 - mean_squared_error: 0.8285Epoch 00015: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8312 - mean_squared_error: 0.8294 - val_loss: 0.9199 - val_mean_squared_error: 0.9199\n",
      "Epoch 17/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8469 - mean_squared_error: 0.8451Epoch 00016: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8283 - mean_squared_error: 0.8265 - val_loss: 0.8692 - val_mean_squared_error: 0.8692\n",
      "Epoch 18/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9031 - mean_squared_error: 0.9013Epoch 00017: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8998 - mean_squared_error: 0.8980 - val_loss: 0.8273 - val_mean_squared_error: 0.8273\n",
      "Epoch 19/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8646 - mean_squared_error: 0.8628Epoch 00018: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8805 - mean_squared_error: 0.8786 - val_loss: 0.9076 - val_mean_squared_error: 0.9076\n",
      "Epoch 20/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9041 - mean_squared_error: 0.9023Epoch 00019: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.9596 - mean_squared_error: 0.9578 - val_loss: 1.3154 - val_mean_squared_error: 1.3154\n",
      "Epoch 21/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.1457 - mean_squared_error: 1.1439Epoch 00020: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.1032 - mean_squared_error: 1.1014 - val_loss: 0.8367 - val_mean_squared_error: 0.8367\n",
      "Epoch 22/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.0345 - mean_squared_error: 1.0327Epoch 00021: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.0417 - mean_squared_error: 1.0399 - val_loss: 0.7254 - val_mean_squared_error: 0.7254\n",
      "Epoch 23/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9846 - mean_squared_error: 0.9828Epoch 00022: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.9738 - mean_squared_error: 0.9720 - val_loss: 0.9918 - val_mean_squared_error: 0.9918\n",
      "Epoch 24/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9890 - mean_squared_error: 0.9871Epoch 00023: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.0268 - mean_squared_error: 1.0250 - val_loss: 0.7672 - val_mean_squared_error: 0.7672\n",
      "Epoch 25/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.4885 - mean_squared_error: 1.4866Epoch 00024: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.3945 - mean_squared_error: 1.3926 - val_loss: 1.7537 - val_mean_squared_error: 1.7537\n",
      "Epoch 26/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.3860 - mean_squared_error: 1.3842Epoch 00025: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.3451 - mean_squared_error: 1.3432 - val_loss: 0.8445 - val_mean_squared_error: 0.8445\n",
      "Epoch 27/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9993 - mean_squared_error: 0.9975Epoch 00026: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.0464 - mean_squared_error: 1.0445 - val_loss: 0.7612 - val_mean_squared_error: 0.7612\n",
      "Epoch 28/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.0186 - mean_squared_error: 1.0167Epoch 00027: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.0759 - mean_squared_error: 1.0740 - val_loss: 1.4992 - val_mean_squared_error: 1.4992\n",
      "Epoch 29/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.1718 - mean_squared_error: 1.1699Epoch 00028: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.1164 - mean_squared_error: 1.1145 - val_loss: 0.9180 - val_mean_squared_error: 0.9180\n",
      "Epoch 30/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9007 - mean_squared_error: 0.8988Epoch 00029: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8995 - mean_squared_error: 0.8976 - val_loss: 0.8311 - val_mean_squared_error: 0.8311\n",
      "Epoch 31/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8468 - mean_squared_error: 0.8449Epoch 00030: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8547 - mean_squared_error: 0.8528 - val_loss: 0.8115 - val_mean_squared_error: 0.8115\n",
      "Epoch 32/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.8160 - mean_squared_error: 0.8141Epoch 00031: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.8724 - mean_squared_error: 0.8705 - val_loss: 1.2059 - val_mean_squared_error: 1.2059\n",
      "Epoch 33/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 0.9515 - mean_squared_error: 0.9495Epoch 00032: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 0.9621 - mean_squared_error: 0.9601 - val_loss: 0.7881 - val_mean_squared_error: 0.7881\n",
      "Epoch 34/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.3958 - mean_squared_error: 1.3938Epoch 00033: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.5154 - mean_squared_error: 1.5135 - val_loss: 0.7585 - val_mean_squared_error: 0.7585\n",
      "Epoch 35/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.5503 - mean_squared_error: 1.5483Epoch 00034: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.5459 - mean_squared_error: 1.5439 - val_loss: 1.8195 - val_mean_squared_error: 1.8195\n",
      "Epoch 36/500\n",
      "2048/2385 [========================>.....] - ETA: 0s - loss: 1.4127 - mean_squared_error: 1.4107Epoch 00035: val_loss did not improve\n",
      "2385/2385 [==============================] - 1s - loss: 1.3349 - mean_squared_error: 1.3329 - val_loss: 1.4979 - val_mean_squared_error: 1.4979\n",
      "Epoch 00035: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lr = 1e-5#learning rate\n",
    "reg = 1e-3\n",
    "print 'building model'\n",
    "nb_filters=32\n",
    "model = Sequential()\n",
    "model.add(LSTM(256,  W_regularizer=l2(reg),return_sequences=True, input_shape=(4,113)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(128,  W_regularizer=l2(reg),return_sequences=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128,  W_regularizer=l2(reg),return_sequences=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64,  W_regularizer=l2(reg),return_sequences=True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Convolution1D(8,64, border_mode='same', W_regularizer=l2(reg),input_shape=(4,113))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Convolution1D(4,32, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Convolution1D(4,32, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Convolution1D(4,32, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Convolution1D(8,64, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(Convolution1D(4,32, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.05))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "print 'compiling model'\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"bestmodel3D.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "X_valid=np.transpose(validmat['tr'][0][0][0],axes=(0,2,1))\n",
    "# X_valid=np.expand_dims(X_valid)\n",
    "y_valid=np.array(validmat['tr'][0][0][1]).squeeze()\n",
    "\n",
    "\n",
    "history=model.fit(X_train, y_train, batch_size=512, nb_epoch=500, shuffle=True, validation_data=(X_valid, y_valid),callbacks=[checkpointer,earlystopper])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "31685/31685 [==============================] - 5s     \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1 (LSTM)                    (None, 4, 256)        378880      lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 4, 256)        0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4, 256)        0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 4, 128)        197120      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 128)        0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 128)        0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 4, 128)        131584      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4, 128)        0           lstm_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4, 128)        0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, 4, 64)         49408       dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 4, 64)         0           lstm_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 4, 64)         0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 256)           0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1000)          257000      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             1001        dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1014993\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "out=model.predict(X_train, batch_size=512,verbose=1)\n",
    "plt.plot(y_train,out,'ro')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31685,)\n",
      "0.845447373944\n",
      "0.578251850801\n",
      "-0.0150249163664\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "out=out.squeeze()\n",
    "print out.shape\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y_train, out)\n",
    "print r_value\n",
    "print slope\n",
    "print intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "3521/3521 [==============================] - 0s     \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_5 (LSTM)                    (None, 4, 256)        378880      lstm_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 4, 256)        0           lstm_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4, 256)        0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                    (None, 4, 128)        197120      dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 4, 128)        0           lstm_6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 4, 128)        0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                    (None, 4, 64)         49408       dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 4, 64)         0           lstm_7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)              (None, 4, 64)         0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                    (None, 4, 64)         33024       dropout_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 4, 64)         0           lstm_8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)              (None, 4, 64)         0           activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 256)           0           dropout_8[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 1000)          257000      flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             1001        dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 916433\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "X_test=np.transpose(testmat['tr'][0][0][0],axes=(0,2,1))\n",
    "y_test=np.array(testmat['tr'][0][0][1]).squeeze()\n",
    "\n",
    "y_out=model.predict(X_test, batch_size=512,verbose=1)\n",
    "plt.plot(y_test,y_out,'ro')\n",
    "plt.ylabel('model prediction')\n",
    "plt.xlabel('FACS-seq data')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3521,)\n",
      "0.614309069504\n",
      "0.446675731966\n",
      "0.0750343296178\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "out=y_out.squeeze()\n",
    "print out.shape\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y_test, out)\n",
    "print r_value\n",
    "print slope\n",
    "print intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_squared_error', 'loss', 'val_mean_squared_error', 'val_loss']\n"
     ]
    }
   ],
   "source": [
    "print history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jx/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "np.random.seed(1337) # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D,Convolution2D, MaxPooling1D\n",
    "from keras.regularizers import l2, activity_l1\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22059, 8, 60)\n",
      "(22059,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "validmat = scipy.io.loadmat('valid3D.mat')\n",
    "testmat = scipy.io.loadmat('test3D.mat')\n",
    "trainmat = scipy.io.loadmat('train3D.mat')\n",
    "\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['tr'][0][0][0]),axes=(0,2,1))\n",
    "# X_train = np.expand_dims(X_train,axis=(2))\n",
    "y_train = np.array(trainmat['tr'][0][0][1]).squeeze()\n",
    "# y_train = y_train.reshape((-1, 1))\n",
    "# y_train.squeeze()\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "compiling model\n",
      "Train on 22059 samples, validate on 2758 samples\n",
      "Epoch 1/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0554 - mean_squared_error: 0.0297Epoch 00000: val_loss improved from inf to 0.01598, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0552 - mean_squared_error: 0.0296 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 2/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0308 - mean_squared_error: 0.0178Epoch 00001: val_loss improved from 0.01598 to 0.01574, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0308 - mean_squared_error: 0.0178 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 3/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0237 - mean_squared_error: 0.0172Epoch 00002: val_loss improved from 0.01574 to 0.01571, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0237 - mean_squared_error: 0.0172 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0168Epoch 00003: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0203 - mean_squared_error: 0.0168 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 5/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0188 - mean_squared_error: 0.0167Epoch 00004: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0187 - mean_squared_error: 0.0167 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 6/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0167Epoch 00005: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0180 - mean_squared_error: 0.0167 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 7/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0166Epoch 00006: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0175 - mean_squared_error: 0.0166 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 8/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0165Epoch 00007: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0171 - mean_squared_error: 0.0165 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 9/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0164Epoch 00008: val_loss improved from 0.01571 to 0.01571, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0169 - mean_squared_error: 0.0164 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 10/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0164Epoch 00009: val_loss improved from 0.01571 to 0.01570, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0167 - mean_squared_error: 0.0164 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 11/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0165Epoch 00010: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0167 - mean_squared_error: 0.0164 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 12/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0164Epoch 00011: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0166 - mean_squared_error: 0.0164 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 13/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0164Epoch 00012: val_loss improved from 0.01570 to 0.01567, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 14/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0163Epoch 00013: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0165 - mean_squared_error: 0.0163 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 15/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00014: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0163 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 16/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00015: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0164 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 17/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00016: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0163 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 18/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00017: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0163 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 19/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00018: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0163 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 20/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0161Epoch 00019: val_loss improved from 0.01567 to 0.01566, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 21/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162Epoch 00020: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 22/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0161Epoch 00021: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0161 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 23/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0161Epoch 00022: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 24/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0161Epoch 00023: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 25/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162Epoch 00024: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 26/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0161Epoch 00025: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 27/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161Epoch 00026: val_loss improved from 0.01566 to 0.01566, saving model to bestmodel3D.hdf5\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 28/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0160Epoch 00027: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 29/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0160Epoch 00028: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 30/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161Epoch 00029: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 31/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0161Epoch 00030: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 32/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0162 - mean_squared_error: 0.0162Epoch 00031: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 33/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161Epoch 00032: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 34/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0161Epoch 00033: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 35/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0160Epoch 00034: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 36/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0160Epoch 00035: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
      "Epoch 37/500\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0160Epoch 00036: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 38/500\n",
      "21760/22059 [============================>.] - ETA: 0s - loss: 0.0161 - mean_squared_error: 0.0160Epoch 00037: val_loss did not improve\n",
      "22059/22059 [==============================] - 0s - loss: 0.0161 - mean_squared_error: 0.0160 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 00037: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132a1a990>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lr = 1e-6#learning rate\n",
    "reg = 1e-3\n",
    "print 'building model'\n",
    "nb_filters=32\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,  W_regularizer=l2(reg),return_sequences=True, input_shape=(8, 60)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(LSTM(64,  W_regularizer=l2(reg),return_sequences=True)) # return sequences is needed for stacking\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128,  W_regularizer=l2(reg)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(30))\n",
    "# model.add(Flatten( input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "# model.add(LSTM(32,24, W_regularizer=l2(reg),input_shape=(X_train.shape[0], X_train.shape[1], X_train.shape[2]))) # adding conv layer collapses output\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "model.add(Convolution1D(4,12, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution1D(8,12, border_mode='same', W_regularizer=l2(reg))) # adding conv layer collapses output\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# model.add(Dense(30))\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "\n",
    "print 'compiling model'\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"bestmodel3D.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "X_valid=np.transpose(validmat['v'][0][0][0],axes=(0,2,1))\n",
    "# X_valid=np.expand_dims(X_valid)\n",
    "y_valid=np.array(validmat['v'][0][0][1]).squeeze()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, nb_epoch=500, shuffle=True, validation_data=(X_valid, y_valid),callbacks=[checkpointer,earlystopper])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "22016/22059 [============================>.] - ETA: 0s____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_1 (LSTM)                    (None, 8, 64)         32000       lstm_input_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 8, 64)         0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 8, 64)         0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 8, 16)         16400       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 8, 16)         0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 8, 16)         0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_2 (Convolution1D)  (None, 8, 8)          520         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 8, 8)          0           convolution1d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 8, 8)          0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 64)            0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             65          flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 48985\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "out=model.predict(X_train, batch_size=512,verbose=1)\n",
    "plt.plot(y_train,out,'ro')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "2757/2757 [==============================] - 0s     \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_2 (LSTM)                    (None, 8, 64)         32000       lstm_input_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 8, 64)         0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 8, 64)         0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_3 (Convolution1D)  (None, 8, 16)         16400       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 8, 16)         0           convolution1d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 8, 16)         0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_4 (Convolution1D)  (None, 8, 8)          520         dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 8, 8)          0           convolution1d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 8, 8)          0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 64)            0           dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1)             65          flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 48985\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "X_test=np.transpose(testmat['tt'][0][0][0],axes=(0,2,1))\n",
    "y_test=np.array(testmat['tt'][0][0][1]).squeeze()\n",
    "\n",
    "out=model.predict(X_test, batch_size=512,verbose=1)\n",
    "plt.plot(y_test,out,'ro')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

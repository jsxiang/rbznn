{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jx/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "np.random.seed(1337) # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution1D,Convolution2D, MaxPooling1D\n",
    "from keras.regularizers import l2, activity_l1\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras import initializations\n",
    "\n",
    "def my_init(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.01, name=name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22059, 2, 4, 12)\n",
      "(22059,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validmat = scipy.io.loadmat('valid4D_mid16.mat')\n",
    "testmat = scipy.io.loadmat('test4D_mid16.mat')\n",
    "trainmat = scipy.io.loadmat('train4D_mid16.mat')\n",
    "\n",
    "\n",
    "X_train = np.transpose(np.array(trainmat['tr'][0][0][0]),axes=(0,2,3,1))\n",
    "y_train = np.array(trainmat['tr'][0][0][1]).squeeze()\n",
    "# y_train = y_train.reshape((-1, 1))\n",
    "# y_train.squeeze()\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "compiling model\n",
      "Train on 22059 samples, validate on 2758 samples\n",
      "Epoch 1/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0837 - mean_squared_error: 0.0835Epoch 00000: val_loss improved from inf to 0.01784, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0836 - mean_squared_error: 0.0834 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 2/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0208Epoch 00001: val_loss improved from 0.01784 to 0.01751, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0210 - mean_squared_error: 0.0208 - val_loss: 0.0175 - val_mean_squared_error: 0.0175\n",
      "Epoch 3/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0195 - mean_squared_error: 0.0193Epoch 00002: val_loss improved from 0.01751 to 0.01694, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0195 - mean_squared_error: 0.0193 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 4/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0189 - mean_squared_error: 0.0187Epoch 00003: val_loss improved from 0.01694 to 0.01687, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0189 - mean_squared_error: 0.0187 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 5/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0184 - mean_squared_error: 0.0182Epoch 00004: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0184 - mean_squared_error: 0.0182 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 6/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0180 - mean_squared_error: 0.0179Epoch 00005: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0180 - mean_squared_error: 0.0179 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 7/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0176Epoch 00006: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0178 - mean_squared_error: 0.0176 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 8/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0178 - mean_squared_error: 0.0176Epoch 00007: val_loss improved from 0.01687 to 0.01686, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0178 - mean_squared_error: 0.0177 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 9/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0174Epoch 00008: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0175 - mean_squared_error: 0.0174 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 10/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0173Epoch 00009: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0174 - mean_squared_error: 0.0173 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 11/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0170Epoch 00010: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0172 - mean_squared_error: 0.0171 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 12/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0173 - mean_squared_error: 0.0172Epoch 00011: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0173 - mean_squared_error: 0.0172 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 13/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0172 - mean_squared_error: 0.0171Epoch 00012: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0172 - mean_squared_error: 0.0171 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 14/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0171 - mean_squared_error: 0.0170Epoch 00013: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0171 - mean_squared_error: 0.0170 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 15/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0169Epoch 00014: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 16/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0169Epoch 00015: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0170 - mean_squared_error: 0.0169 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 17/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0170 - mean_squared_error: 0.0169Epoch 00016: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0170 - mean_squared_error: 0.0169 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 18/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0169Epoch 00017: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 19/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0169 - mean_squared_error: 0.0168Epoch 00018: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0169 - mean_squared_error: 0.0168 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 20/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0168Epoch 00019: val_loss improved from 0.01686 to 0.01684, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0169 - mean_squared_error: 0.0168 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 21/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0166Epoch 00020: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 22/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0166Epoch 00021: val_loss improved from 0.01684 to 0.01683, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0167 - mean_squared_error: 0.0166 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 23/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0167Epoch 00022: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0168 - mean_squared_error: 0.0167 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 24/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0167Epoch 00023: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0168 - mean_squared_error: 0.0167 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 25/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0166Epoch 00024: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0167 - mean_squared_error: 0.0166 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 26/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0166Epoch 00025: val_loss improved from 0.01683 to 0.01683, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 27/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0167 - mean_squared_error: 0.0166Epoch 00026: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0167 - mean_squared_error: 0.0166 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 28/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0165Epoch 00027: val_loss improved from 0.01683 to 0.01678, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0166 - mean_squared_error: 0.0165 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 29/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0165Epoch 00028: val_loss improved from 0.01678 to 0.01677, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0166 - mean_squared_error: 0.0165 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 30/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165Epoch 00029: val_loss improved from 0.01677 to 0.01677, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 31/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0165Epoch 00030: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 32/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0164Epoch 00031: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 33/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0164Epoch 00032: val_loss improved from 0.01677 to 0.01676, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 34/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0164Epoch 00033: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 35/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0164Epoch 00034: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 36/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0164Epoch 00035: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 37/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0166 - mean_squared_error: 0.0165Epoch 00036: val_loss improved from 0.01676 to 0.01675, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 38/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0165Epoch 00037: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 39/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0163Epoch 00038: val_loss improved from 0.01675 to 0.01673, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0164 - mean_squared_error: 0.0163 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 40/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0163Epoch 00039: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0165 - mean_squared_error: 0.0164 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 41/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0165 - mean_squared_error: 0.0164Epoch 00040: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0164 - mean_squared_error: 0.0163 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 42/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00041: val_loss improved from 0.01673 to 0.01673, saving model to bestmodel4D_mid16redo.hdf5\n",
      "22059/22059 [==============================] - 2s - loss: 0.0163 - mean_squared_error: 0.0162 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 43/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0163Epoch 00042: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0164 - mean_squared_error: 0.0163 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 44/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0163Epoch 00043: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0164 - mean_squared_error: 0.0162 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
      "Epoch 45/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0164 - mean_squared_error: 0.0163Epoch 00044: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0164 - mean_squared_error: 0.0163 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 46/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162Epoch 00045: val_loss did not improve\n",
      "22059/22059 [==============================] - 2s - loss: 0.0164 - mean_squared_error: 0.0162 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 47/1000\n",
      "22016/22059 [============================>.] - ETA: 0s - loss: 0.0163 - mean_squared_error: 0.0162"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lr = 1e-6#learning rate\n",
    "reg = 1e-3\n",
    "print 'building model'\n",
    "nb_filters=32\n",
    "model = Sequential()\n",
    "# model.add(LSTM(32,  W_regularizer=l2(reg),return_sequences=True, input_shape=(4, 113)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(64,  W_regularizer=l2(reg),return_sequences=True)) # return sequences is needed for stacking\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(128,  W_regularizer=l2(reg)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(30))\n",
    "# model.add(Flatten( input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])))\n",
    "\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "\n",
    "model.add(Convolution2D(4, 2,12, border_mode='same', W_regularizer=l2(reg),init=my_init,input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]))) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(4, 2,12, border_mode='same', W_regularizer=l2(reg),init=my_init)) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(4, 2,12, border_mode='same', W_regularizer=l2(reg),init=my_init)) # adding conv layer collapses output\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# model.add(Dense(30))\n",
    "model.add(Dense(1))\n",
    "adam = Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "\n",
    "print 'compiling model'\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"bestmodel4D_mid16redo.hdf5\", verbose=1, save_best_only=True)\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
    "\n",
    "X_valid=np.transpose(validmat['v'][0][0][0],axes=(0,2,3,1))\n",
    "y_valid=np.array(validmat['v'][0][0][1]).squeeze()\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, nb_epoch=1000, shuffle=True, validation_data=(X_valid, y_valid),callbacks=[checkpointer,earlystopper])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22016/22059 [============================>.] - ETA: 0s____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 4, 4, 12)      196         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 4, 4, 12)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 4, 4, 12)      0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 4, 4, 12)      260         dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 4, 4, 12)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 4, 4, 12)      0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 4, 4, 12)      132         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4, 4, 12)      0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4, 4, 12)      0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 192)           0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             193         flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 781\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out=model.predict(X_train, batch_size=512,verbose=1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ce3e390>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(y_train,out,'ro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "2757/2757 [==============================] - 0s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e637790>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "X_test=np.transpose(testmat['tt'][0][0][0],axes=(0,2,3,1))\n",
    "\n",
    "y_test=np.array(testmat['tt'][0][0][1]).squeeze()\n",
    "\n",
    "outtest=model.predict(X_test, batch_size=512,verbose=1)\n",
    "plt.plot(y_test,outtest,'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
